{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbgBCY4FZL5b"
   },
   "source": [
    "# Scott Breitbach\n",
    "## 28-May-2022\n",
    "# LSTM AI Text Generator\n",
    "## Trained using text of *The Ultimate Hitchiker's Guide to the Galaxy* by Douglas Adams\n",
    "Source [text](https://archive.org/stream/TheultimateHitchhikersGuide/The%20Hitchhiker%27s%20Guide%20To%20The%20Galaxy_djvu.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFS-KDgxZ5dQ"
   },
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ny09m9gn6-d6",
    "outputId": "ef2309c5-9266-47f0-f75f-46cca924bd9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 1561887\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "\n",
    "# set seed\n",
    "np.random.seed(seed=42)\n",
    "\n",
    "# get data\n",
    "path = 'data/h2g2.txt'\n",
    "text = open(path).read().lower()\n",
    "print(f'Corpus length: {len(text)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5LOlgSOaKcj"
   },
   "source": [
    "## Vectorize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2Oj45KK5VBS",
    "outputId": "edc0062a-4d78-4680-b82e-8691046d2758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 520609\n",
      "Unique characters: 60\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing sequences of characters\n",
    "maxlen = 60     # Extract sequences of 60 characters\n",
    "step = 3        # Sample a new sequence every three characters\n",
    "sentences = []  # Holds extracted sequences\n",
    "next_chars = [] # Holds targets (the follow-up characters)\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print(f'Number of sequences: {len(sentences)}')\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text))) \n",
    "print(f'Unique characters: {len(chars)}')\n",
    "\n",
    "# Dict that maps unique characters to their index in the list `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars) \n",
    "\n",
    "print('Vectorization...')\n",
    "# One-hot encodes the caracters into binary arrays:\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuGZYsa6aOg2"
   },
   "source": [
    "## Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WhsI4Rar61-m"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'tf2' from 'tensorflow.python' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_644/2621120358.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Single-layer LSTM model for next-character prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'tf2' from 'tensorflow.python' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Set up single-layer LSTM model for next-character prediction\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKfO5ojY77vQ"
   },
   "outputs": [],
   "source": [
    "# Model compilation configuration\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-su08G37-oL"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    '''\n",
    "    Sample the next character given the model's predictions\n",
    "    '''\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsnni1-CaVd5"
   },
   "source": [
    "## Fit the model\n",
    "Note: the text turned to gibberish around Epoch 25, so I set it to stop early at Epoch 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7RXGL1N8IOB",
    "outputId": "dcfe2c76-f3c6-4968-ae8c-d7c55c629aaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "4068/4068 [==============================] - 775s 190ms/step - loss: 1.7283\n",
      "\n",
      "Epoch 2\n",
      "4068/4068 [==============================] - 774s 190ms/step - loss: 1.4932\n",
      "\n",
      "Epoch 3\n",
      "4068/4068 [==============================] - 775s 190ms/step - loss: 1.4354\n",
      "\n",
      "Epoch 4\n",
      "4068/4068 [==============================] - 772s 190ms/step - loss: 1.4078\n",
      "\n",
      "Epoch 5\n",
      "4068/4068 [==============================] - 774s 190ms/step - loss: 1.3895\n",
      "\n",
      "Epoch 6\n",
      "4068/4068 [==============================] - 773s 190ms/step - loss: 1.3757\n",
      "\n",
      "Epoch 7\n",
      "4068/4068 [==============================] - 776s 191ms/step - loss: 1.3657\n",
      "\n",
      "Epoch 8\n",
      "4068/4068 [==============================] - 789s 194ms/step - loss: 1.3563\n",
      "\n",
      "Epoch 9\n",
      "4068/4068 [==============================] - 796s 196ms/step - loss: 1.3495\n",
      "\n",
      "Epoch 10\n",
      "4068/4068 [==============================] - 788s 194ms/step - loss: 1.3437\n",
      "\n",
      "Epoch 11\n",
      "4068/4068 [==============================] - 781s 192ms/step - loss: 1.3388\n",
      "\n",
      "Epoch 12\n",
      "4068/4068 [==============================] - 785s 193ms/step - loss: 1.3354\n",
      "\n",
      "Epoch 13\n",
      "4068/4068 [==============================] - 779s 192ms/step - loss: 1.3291\n",
      "\n",
      "Epoch 14\n",
      "4068/4068 [==============================] - 787s 194ms/step - loss: 1.3274\n",
      "\n",
      "Epoch 15\n",
      "4068/4068 [==============================] - 793s 195ms/step - loss: 1.3237\n",
      "\n",
      "Epoch 16\n",
      "4068/4068 [==============================] - 790s 194ms/step - loss: 1.3211\n",
      "\n",
      "Epoch 17\n",
      "4068/4068 [==============================] - 791s 194ms/step - loss: 1.3204\n",
      "\n",
      "Epoch 18\n",
      "4068/4068 [==============================] - 791s 194ms/step - loss: 1.3198\n",
      "\n",
      "Epoch 19\n",
      "4068/4068 [==============================] - 799s 197ms/step - loss: 1.3184\n",
      "\n",
      "Epoch 20\n",
      "4068/4068 [==============================] - 800s 197ms/step - loss: 1.3165\n",
      "\n",
      "Epoch 21\n",
      "4068/4068 [==============================] - 804s 198ms/step - loss: 1.3175\n",
      "\n",
      "Epoch 22\n",
      "4068/4068 [==============================] - 797s 196ms/step - loss: 1.3232\n"
     ]
    }
   ],
   "source": [
    "# Text-generation loop\n",
    "import random\n",
    "import sys\n",
    "for epoch in range(1, 23):#60): # Trains model for 60 epochs\n",
    "    print(f'\\nEpoch {epoch}:')\n",
    "    model.fit(x, y, batch_size=128, epochs=1) # Fits model for 1 iteration of data\n",
    "    # Generate example text every third epoch while training:\n",
    "    if epoch % 3 == 0:\n",
    "        # Selects a text seed at random:\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "        generated_text = text[start_index: start_index + maxlen]\n",
    "        print(f'---\\nGenerating with seed:\\n\"{generated_text}\"\\n---')\n",
    "        for temperature in [0.2, 0.5, 1.0]:#, 1.2]: # Tries a range of different sampling temperatures\n",
    "            print(f'\\n------ temperature: {temperature}\\n')\n",
    "            sys.stdout.write(generated_text)\n",
    "            for i in range(200): # Generates 200 characters, starting from seed text\n",
    "                # One-hot encodes characters generated so far:\n",
    "                sampled = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(generated_text):\n",
    "                    sampled[0, t, char_indices[char]] = 1.\n",
    "                # Samples the next character\n",
    "                preds = model.predict(sampled, verbose=0)[0]\n",
    "                next_index = sample(preds, temperature)\n",
    "                next_char = chars[next_index]\n",
    "                generated_text += next_char\n",
    "                generated_text = generated_text[1:]\n",
    "                sys.stdout.write(next_char)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln-TVQ6can63"
   },
   "source": [
    "## Generate text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1UThka825ny",
    "outputId": "b4190956-e111-4615-d746-5a809f71fa6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating with seed: \"id. \"the most powerful computational force \n",
      "known to parasci\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "id. \"the most powerful computational force \n",
      "known to parascion and most time,\" said the old brie into and \n",
      "would be into the crowd money of more of the planet of a contrance \n",
      "and the door of the planet of the mind can about the beamer \n",
      "direction to the angric from the ship, so only sure a big was \n",
      "about in the stare of things were contrations of the answer \n",
      "to have something suddenly to do anything and means to be the \n",
      "thing it was controlobinitely because\n"
     ]
    }
   ],
   "source": [
    "# Selects a text seed at random:\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "generated_text = text[start_index: start_index + maxlen]\n",
    "print(f'---\\nGenerating with seed:\\n\"{generated_text}\"\\n---')\n",
    "for temperature in [0.2, 0.5, 1.0]: # Tries a range of different sampling temperatures\n",
    "    print(f'\\n------ temperature: {temperature}\\n')\n",
    "    sys.stdout.write(generated_text)\n",
    "    for i in range(400): # Generates 400 characters, starting from seed text\n",
    "        # One-hot encodes characters generated so far:\n",
    "        sampled = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(generated_text):\n",
    "            sampled[0, t, char_indices[char]] = 1.\n",
    "        # Samples the next character\n",
    "        preds = model.predict(sampled, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = chars[next_index]\n",
    "        generated_text += next_char\n",
    "        generated_text = generated_text[1:]\n",
    "        sys.stdout.write(next_char)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 20 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Slf1UgSdYP5E",
    "outputId": "2003e95c-b279-461e-cc0d-ad888ff41342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==GENERATED TEXT #1:\n",
      "\n",
      "--- Generating with seed: \" to be \n",
      "beautiful. am i?\" \n",
      "\n",
      "\"you're pretty direct, aren't yo\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      " to be \n",
      "beautiful. am i?\" \n",
      "\n",
      "\"you're pretty direct, aren't you to erotion you stream, and \n",
      "then at the trees of the planet that was one of the strange \n",
      "words because the other of the people of the sort of weight \n",
      "many money and stream, there was back at the million thing and \n",
      "tried in the a man. \n",
      "\n",
      "\"i have been to absoluther,\" said arthur leaded, \"oh it was the \n",
      "still in front of things again when it wasn't world the computer \n",
      "captain, from people on the who\n",
      "\n",
      "==GENERATED TEXT #2:\n",
      "\n",
      "--- Generating with seed: \"eel that very strongly.\" \n",
      "\n",
      "\n",
      "\n",
      "chapter 33 \n",
      "\n",
      "\n",
      "the sun was shini\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "eel that very strongly.\" \n",
      "\n",
      "\n",
      "\n",
      "chapter 33 \n",
      "\n",
      "\n",
      "the sun was shining as the noise. \n",
      "\n",
      "\"you don't know what your manding and and the planet in the floor \n",
      "that was after and with the sheed was as firsted at them to \n",
      "the stories of a stared light and silence because the other \n",
      "full of the consolain carering generally never to be all the \n",
      "corridor and stream of absuring a strange through the towel \n",
      "one controls had to be a one of the big straines, and didn't \n",
      "then th\n",
      "\n",
      "==GENERATED TEXT #3:\n",
      "\n",
      "--- Generating with seed: \" the air. \n",
      "\n",
      "\"a frogstar scout robot class c out looking for \"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      " the air. \n",
      "\n",
      "\"a frogstar scout robot class c out looking for that was reached \n",
      "to be startled was in it. it was a moment of the alare arthur. \n",
      "\n",
      "\"you're that we was standing to the monly stream and tricia \n",
      "was the planet floor and then shoot in the corridor in that \n",
      "seemed a planet who was merelled to mean, the water stood to \n",
      "convente, in his might see it something that probably all the \n",
      "street little things to see it in the note that were something \n",
      "contro\n",
      "\n",
      "==GENERATED TEXT #4:\n",
      "\n",
      "--- Generating with seed: \"rab hold of. they were all thin and, under \n",
      "domestic lightin\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "rab hold of. they were all thin and, under \n",
      "domestic lighting and concented her. \n",
      "\n",
      "\"well,\" said the boat moneors and fell on the slight streek of \n",
      "directional money that the alien of the planet was to abso the \n",
      "damper, then stood in the ship, then the moment of the heart \n",
      "of the histecve"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotines of the speed to be a hitchhas) vhhg !quached \n",
      "then the ship, then then it was the night of instead. \n",
      "\n",
      "\"when it's eventually to see the stores were the your perfectl\n",
      "\n",
      "==GENERATED TEXT #5:\n",
      "\n",
      "--- Generating with seed: \"e in their right minds would want \n",
      "to buy a nowwhattian bogh\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "e in their right minds would want \n",
      "to buy a nowwhattian boghon foot. \n",
      "\n",
      "\"he could have something you now,\" said the robot. \n",
      "\n",
      "\"well, \"i don't know well,\" he said and streeked again. \n",
      "\n",
      "\"what do you was any year?\" \n",
      "\n",
      "arthur stole looked to read to see a set to people the big one \n",
      "one that was now what it was a sand from the million again. \n",
      "\n",
      "\"there was anything to see the moment of the door,\" said known \n",
      "all to the back of the strange as it was capering the stre\n",
      "\n",
      "==GENERATED TEXT #6:\n",
      "\n",
      "--- Generating with seed: \"lier air.\" \n",
      "\n",
      "\"that's one future,\" said harl. \"that's your fu\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "lier air.\" \n",
      "\n",
      "\"that's one future,\" said harl. \"that's your full with the earth. \n",
      "\n",
      "\"there to stoy the your mind cape, and you went to the speacling \n",
      "meant and said, and about the people of the rocket, and it wasn't \n",
      "heard in this and then stood in the miles ending the word into \n",
      "the connect floor was now and then a thing had dropped to watch \n",
      "the special and head. \n",
      "\n",
      "\"i think you can you go to see the guide that will see your mean for \n",
      "the strange control con\n",
      "\n",
      "==GENERATED TEXT #7:\n",
      "\n",
      "--- Generating with seed: \" he said someone has to do something round \n",
      "here.\" \n",
      "\n",
      "\"ah!\", \"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      " he said someone has to do something round \n",
      "here.\" \n",
      "\n",
      "\"ah!\", which was a searchested in this attention. it's the speech \n",
      "behind it had been continued was all designed to the space of \n",
      "the set a little circle and was the man was don't want to me \n",
      "the stories of don't stood of enupterer, but it was something \n",
      "and the mind on the moment that he stood to be the moment and \n",
      "stopped and because it was all to the earth back on the ship \n",
      "had completely before the w\n",
      "\n",
      "==GENERATED TEXT #8:\n",
      "\n",
      "--- Generating with seed: \"e electron ram stabbed out another searing blaze of light an\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "e electron ram stabbed out another searing blaze of light and \n",
      "ordered about the man was a stare of pretty story were a people \n",
      "of the strange message of pergons. \n",
      "\n",
      "\"what do you go with the simple of the mind were a ship,\" he said, \n",
      "and stood to a very instant that was a sigh of the stars of \n",
      "the space. \n",
      "\n",
      "he waited in a moment of the sundions of the corner stood to \n",
      "sure the faice to the alien of the door and standing sighed \n",
      "to the struggle of the ship, f\n",
      "\n",
      "==GENERATED TEXT #9:\n",
      "\n",
      "--- Generating with seed: \" the equally extraordinary sequence \n",
      "of events that had seem\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      " the equally extraordinary sequence \n",
      "of events that had seemed to be seemed to see the brish of the \n",
      "confire. \n",
      "\n",
      "arthur called that the man was a man was an awful sheam which \n",
      "said, \"but he said the door and had a brief that he stared with \n",
      "marvin. \n",
      "\n",
      "\"where were then a million thing, are the sounds that were recordnonally \n",
      "and tricia was one of the struggle. \n",
      "\n",
      "it was in a staring straight leader that is the stream of the \n",
      "controland that is a stared of the \n",
      "\n",
      "==GENERATED TEXT #10:\n",
      "\n",
      "--- Generating with seed: \"\n",
      "the town appeared to consist mostly of fairly low buildings\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "\n",
      "the town appeared to consist mostly of fairly low buildings of \n",
      "mean, slipsed and standing to the old way of herpoued and was \n",
      "attached in the mountain as it was a strange with the word. \n",
      "\n",
      "it was for a sense of the light stared about the vogon light had \n",
      "digouter that so when they were to him more the floor in the \n",
      "tricia could see what what or round which was a startled streek \n",
      "to the staring half things of the particular and the towel. \n",
      "\n",
      "\n",
      "\n",
      "he was had fo\n",
      "\n",
      "==GENERATED TEXT #11:\n",
      "\n",
      "--- Generating with seed: \"what it doesn't go on to say is that though it will usually \"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "what it doesn't go on to say is that though it will usually \n",
      "address the people of this mine of failing to the point. \n",
      "\n",
      "\"well,\" said arthur. \n",
      "\n",
      "\"well,\" said the babblit stood and sat something and with the \n",
      "man was only in about it, the stream of a moment of about the \n",
      "the extreme of the ship, something strieas business with the \n",
      "answered into a tricia stared now filly and a brochure managed \n",
      "to the particular most showed to be one of the planet for a \n",
      "star\n",
      "\n",
      "==GENERATED TEXT #12:\n",
      "\n",
      "--- Generating with seed: \"soon it became \n",
      "clear that a block of the ground, about six \"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "soon it became \n",
      "clear that a block of the ground, about six of the obr\n",
      "partity of the \n",
      "someone decided to wander and the curious strange hands to the \n",
      "consistorical story. the side of his stood was susponaring a \n",
      "party who pleased him to wand down to see up and would netell \n",
      "to be stopped and stopped down and said and into the stary understand \n",
      "with the old man with them his book and anything about that \n",
      "completely teleponsion universe in the rock to hir, \n",
      "\n",
      "==GENERATED TEXT #13:\n",
      "\n",
      "--- Generating with seed: \"with giddy dropping, every part of him screaming but his voi\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "with giddy dropping, every part of him screaming but his voice \n",
      "spagines of the reason that started to find the flevep. \n",
      "\n",
      "\"well,\" he said. \n",
      "\n",
      "\"there was that was a story,\" said arthur were all the sound of \n",
      "the vogon could four the again. \n",
      "\n",
      "\"do you was that you don't wark about it,\" said ford. \n",
      "\n",
      "\"look, i was continured stories,\" shouted arthur that the pause \n",
      "minutes was then stared to be a good computer that were treesibed \n",
      "in the space of astrology, had g\n",
      "\n",
      "==GENERATED TEXT #14:\n",
      "\n",
      "--- Generating with seed: \" \n",
      "because it gave you a little more time to get things done \"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      " \n",
      "because it gave you a little more time to get things done in the \n",
      "all the two of then the galaxy was the small great startled \n",
      "and with the horribly of the infinite than the one of the other \n",
      "paper which was all them and the restaurant of gold in the planet \n",
      "in the now continual story of the sky was the planet of the \n",
      "ship was going to mean?\" \n",
      "\n",
      "\"the manding suddenly to me a simples?\" \n",
      "\n",
      "the lards of the thing in the sport of the surcrous is appludening \n",
      "a\n",
      "\n",
      "==GENERATED TEXT #15:\n",
      "\n",
      "--- Generating with seed: \"go home.\" \n",
      "\n",
      "arthur shook his head. \n",
      "\n",
      "\"what's the matter?\" sh\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "go home.\" \n",
      "\n",
      "arthur shook his head. \n",
      "\n",
      "\"what's the matter?\" she said and had to be being was tone it \n",
      "were all the other staring and there took the bowing stream \n",
      "and stone later. \n",
      "\n",
      "\"there was all don't the same years,\" said arthur. \n",
      "\n",
      "\"that was the galaxy,\" said ford, \"i was also the sun two in \n",
      "the publing ship, and the random in the girl and then streek \n",
      "to the door that is a stared bargors and it was worst to the \n",
      "stories of the floor of the moment that t\n",
      "\n",
      "==GENERATED TEXT #16:\n",
      "\n",
      "--- Generating with seed: \"out the weather and leaves again. \n",
      "\n",
      "\"you seem ill at ease,\" \"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "out the weather and leaves again. \n",
      "\n",
      "\"you seem ill at ease,\" said arthur with the controls to be \n",
      "played to explain the made to be exactly anything in the two \n",
      "screenally engineer in the sort of probably wondered and told \n",
      "walk and stopped before the story did who flashed by the search \n",
      "in the ownery of the mind of the stories was a tree. \n",
      "\n",
      "\"well,\" said arthur. \n",
      "\n",
      "\"what is the strange,\" said ford. \n",
      "\n",
      "\"the door was the storter somethinzbull of the mount to be \n",
      "\n",
      "==GENERATED TEXT #17:\n",
      "\n",
      "--- Generating with seed: \" said marvin, \"i've never been there.\" \n",
      "\n",
      "\"why,\" said ford sq\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      " said marvin, \"i've never been there.\" \n",
      "\n",
      "\"why,\" said ford squally galaxy. \n",
      "\n",
      "\"what is seemed to see to be all stomping the staring years \n",
      "of the particular stared and then the storics of the other publich \n",
      "black that he was another cancely best and spaces and worth \n",
      "times and streamed the other moment, and was none completely \n",
      "arthur. \n",
      "\n",
      "\"there!\" \n",
      "\n",
      "he started but it was one of the street his content of the seconds \n",
      "that is dears of that astosing and the chap\n",
      "\n",
      "==GENERATED TEXT #18:\n",
      "\n",
      "--- Generating with seed: \"ou,\" said wonko the sane, \"the \n",
      "sandals? i have them. i'll g\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "ou,\" said wonko the sane, \"the \n",
      "sandals? i have them. i'll get themself. pretty that you were \n",
      "then the hands that is that was like to me of the not on the \n",
      "street of cultion. \n",
      "\n",
      "he was a service at him, it was a moment of a countication of \n",
      "difficult of the ship. \n",
      "\n",
      "\"i'm not the story of the mind is a probably spaces he stolen out \n",
      "in the strange life that it was with a stories and stream and \n",
      "started to the earth of the miles of the storily and matural \n",
      "st\n",
      "\n",
      "==GENERATED TEXT #19:\n",
      "\n",
      "--- Generating with seed: \"dance\" and it said \"see under advice\". he \n",
      "looked up \"advice\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      "dance\" and it said \"see under advice\". he \n",
      "looked up \"advices under the most planet which was the battle \n",
      "record moment and don't light what all you called to wand and \n",
      "the stare to count the point of the realizer not actually the \n",
      "ship was descenders of moves of a fleet of people of the restaurant \n",
      "of the galaxy, and done in the old protears of the hands of \n",
      "the large to completely his street into the collimonel of the \n",
      "building to make the ground got thr\n",
      "\n",
      "==GENERATED TEXT #20:\n",
      "\n",
      "--- Generating with seed: \" and written on it, in \n",
      "large friendly letters, the words \"d\"\n",
      "\n",
      "------ temperature: 0.5 \n",
      "\n",
      " and written on it, in \n",
      "large friendly letters, the words \"do you said and that was \n",
      "all in the same storily and started about it. \n",
      "\n",
      "\"you never called it,\" said arthur were with the moment, that \n",
      "instead, there was a people to conversation of a probably stare \n",
      "of the galaxy, that stood that he had been then stared and so \n",
      "days, the stooness were waited it, and then the infinitely pull \n",
      "way about him with the galaxy, and and then she was a little \n",
      "backwards\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    print(f'\\n== GENERATED TEXT #{i+1}: ==\\n')\n",
    "    # Selects a text seed at random:\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print(f'---\\nGenerating with seed:\\n\"{generated_text}\"\\n---\\n')\n",
    "    temperature = 0.5\n",
    "    sys.stdout.write(generated_text)\n",
    "    for i in range(400): # Generates 400 characters, starting from seed text\n",
    "        # One-hot encodes characters generated so far:\n",
    "        sampled = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(generated_text):\n",
    "            sampled[0, t, char_indices[char]] = 1.\n",
    "        # Samples the next character\n",
    "        preds = model.predict(sampled, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = chars[next_index]\n",
    "        generated_text += next_char\n",
    "        generated_text = generated_text[1:]\n",
    "        sys.stdout.write(next_char)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEotgXQSYVHn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BreitbachScott_Assignment 11.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
